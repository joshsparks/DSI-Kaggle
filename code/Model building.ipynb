{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the files\n",
    "train_data = pd.read_csv('../assets/train_complete_mg.csv')\n",
    "test_data = pd.read_csv('../assets/test_complete_mg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Continuing to borrow Ritika's EDA function.\n",
    "# Need to ensure types are workable\n",
    "\n",
    "def eda(dataframe):\n",
    "    print \"dataframe types \\n\", dataframe.dtypes, \"\\n\"\n",
    "    print \"dataframe shape \\n\", dataframe.shape, \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe types \n",
      "Species                   object\n",
      "Block                      int64\n",
      "Trap                      object\n",
      "Latitude                 float64\n",
      "Longitude                float64\n",
      "AddressAccuracy            int64\n",
      "NumMosquitos               int64\n",
      "WnvPresent                 int64\n",
      "YMD                       object\n",
      "PIPIENS                    int64\n",
      "RESTUANS                   int64\n",
      "SALINARIUS                 int64\n",
      "TERRITANS                  int64\n",
      "Station                    int64\n",
      "Tmax                       int64\n",
      "Tmin                       int64\n",
      "DewPoint                   int64\n",
      "WetBulb                  float64\n",
      "Sunrise                   object\n",
      "Sunset                    object\n",
      "PrecipTotal              float64\n",
      "StnPressure              float64\n",
      "SeaLevel                 float64\n",
      "ResultSpeed              float64\n",
      "ResultDir                  int64\n",
      "AvgSpeed                 float64\n",
      "Tavg_int                   int64\n",
      "Normal_Temp              float64\n",
      "Depart_calc              float64\n",
      "RA                         int64\n",
      "BR                         int64\n",
      "TS                         int64\n",
      "HZ                         int64\n",
      "SN                         int64\n",
      "FG                         int64\n",
      "FG+                        int64\n",
      "FU                         int64\n",
      "DZ                         int64\n",
      "VC                         int64\n",
      "MI                         int64\n",
      "BC                         int64\n",
      "Days_Since_Spray           int64\n",
      "Dist_to_Closest_Spray    float64\n",
      "Week                       int64\n",
      "DaylightMinutes            int64\n",
      "dtype: object \n",
      "\n",
      "dataframe shape \n",
      "(9693, 45) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "eda(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Mega Function to run all of the models of relevance ###\n",
    "# Mostly derived from 6.08 work and Project 3, with a couple modifications #\n",
    "\n",
    "### NEED TO MODIFY FUNCTION BEFORE RUNNING MODEL \n",
    "### IF WISHING TO USE model_metric (also needs commented back in)\n",
    "\n",
    "### Scale = \"Yes\"; skip otherwise\n",
    "### TTS = \"Yes\" or \"No\" on whether or not to run a train/test split\n",
    "### Boost = \"Yes\"; skip otherwise\n",
    "### X = Pre-defined dataframe and its columns of interest\n",
    "### y = Pre-defined dataframe target column\n",
    "### model_to_run = Model() wishing to run this test on\n",
    "### grid_search_dictionary = parameter dictionary to feed \n",
    "            ### into grid_search for the model of interest\n",
    "\n",
    "def evaluate_model(Scale, TTS, Boost, X, y, model_to_run, grid_search_dictionary):\n",
    "    \n",
    "    if Scale == \"Yes\":\n",
    "        from sklearn.preprocessing import Normalizer\n",
    "        normalizer = Normalizer()\n",
    "        X = normalizer.fit_transform(X)\n",
    "        \n",
    "    if TTS == \"Yes\":\n",
    "        # Perform the train/test split:\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)   \n",
    "        \n",
    "    if TTS == \"No\":\n",
    "        # Skip TTS:\n",
    "        X_train = X\n",
    "        X_test = X\n",
    "        y_train = y\n",
    "        y_test = y\n",
    "    \n",
    "    ##### Run the model\n",
    "    model = model_to_run\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    probabilities = model.predict_proba(X_test) # Need the second value\n",
    "    \n",
    "    probability_list = [] # Becomes the list of probabilities\n",
    "    for i in probabilities:\n",
    "        probability_list.append(i[1])\n",
    "    probabilities = probability_list\n",
    "        \n",
    "    \n",
    "    # Create cross-val score on train\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    # Perform 10-fold cross validation\n",
    "    trn_cv_scores = cross_val_score(model, X_train, y_train, cv=10)\n",
    "    \n",
    "    # Create scores on test group\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    # Comment in if running a model with this attribute\n",
    "    # model_metric = model.feature_importances_   \n",
    "    # print model_metric\n",
    "    \n",
    "        # Model specific output attribute\n",
    "        # Have to reassign each function run\n",
    "    \n",
    "    acc_score = accuracy_score(y_test, predictions)\n",
    "    con_matrix = confusion_matrix(y_test, predictions)\n",
    "    class_rep = classification_report(y_test, predictions)\n",
    "    roc_auc = roc_auc_score(y_test, probabilities)\n",
    "\n",
    "    \n",
    "    ##### Run Bagging\n",
    "    from sklearn.ensemble import BaggingClassifier\n",
    "    \n",
    "    bagging = BaggingClassifier(base_estimator=model)\n",
    "    bagging.fit(X_train, y_train)\n",
    "    bagging_predictions = bagging.predict(X_test)\n",
    "    bagging_probabilities = bagging.predict_proba(X_test)\n",
    "    \n",
    "    bag_probability_list = [] # Becomes the list of probabilities\n",
    "    for i in bagging_probabilities:\n",
    "        bag_probability_list.append(i[1])\n",
    "    bagging_probabilities = bag_probability_list\n",
    "    \n",
    "    bg_acc_score = accuracy_score(y_test, bagging_predictions)\n",
    "    bg_con_matrix = confusion_matrix(y_test, bagging_predictions)\n",
    "    bg_class_rep = classification_report(y_test, bagging_predictions)\n",
    "    bg_roc_auc = roc_auc_score(y_test, bagging_probabilities)\n",
    "    \n",
    "    \n",
    "    ##### Run a GridSearch\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    # Run 10-fold cross validation on the bagged model\n",
    "    grid_search = GridSearchCV(model, grid_search_dictionary, cv=10, n_jobs = -1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    grid_search_predictions = grid_search.predict(X_test)\n",
    "    grid_search_probabilities = grid_search.predict_proba(X_test)\n",
    "    \n",
    "    gs_probability_list = [] # Becomes the list of probabilities\n",
    "    for i in grid_search_probabilities:\n",
    "        gs_probability_list.append(i[1])\n",
    "    grid_search_probabilities = gs_probability_list\n",
    "    \n",
    "    gs_acc_score = accuracy_score(y_test, grid_search_predictions)\n",
    "    gs_con_matrix = confusion_matrix(y_test, grid_search_predictions)\n",
    "    gs_class_rep = classification_report(y_test, grid_search_predictions)\n",
    "    gs_roc_auc = roc_auc_score(y_test, grid_search_probabilities)\n",
    "    \n",
    "    \n",
    "    # See the outputs\n",
    "    print \"Cross Val Scores \\n\", trn_cv_scores, \"\\n\"\n",
    "    # print \"Model Attribute \\n\", model_metric, \"\\n\"\n",
    "            # Add back in if used above\n",
    "    print \"Accuracy Score \\n\", acc_score, \"\\n\"\n",
    "    print \"Confusion Matrix \\n\", con_matrix, \"\\n\"\n",
    "    print \"Classification Report \\n\", class_rep, \"\\n\"\n",
    "    print \"ROC-AUC Score \\n\", roc_auc, \"\\n\"\n",
    "    \n",
    "    print \"Bagging Classifiers \\n\", bagging.base_estimator_, \"\\n\"\n",
    "    print \"Bagging Accuracy Score \\n\", bg_acc_score, \"\\n\"\n",
    "    print \"Bagging Confusion Matrix \\n\", bg_con_matrix, \"\\n\"\n",
    "    print \"Bagging Classification Report \\n\", bg_class_rep\n",
    "    print \"Bagging ROC-AUC Score \\n\", bg_roc_auc, \"\\n\"\n",
    "    \n",
    "    print \"Grid Search Best Params \\n\", grid_search.best_params_, \"\\n\"\n",
    "    print \"Grid Search Best Score \\n\", grid_search.best_estimator_, \"\\n\"\n",
    "    print \"GS Accuracy Score \\n\", gs_acc_score, \"\\n\"\n",
    "    print \"GS Confusion Matrix \\n\", gs_con_matrix, \"\\n\"\n",
    "    print \"GS Classification Report \\n\", gs_class_rep, \"\\n\"\n",
    "    print \"GS ROC-AUC Score \\n\", gs_roc_auc, \"\\n\"\n",
    "    \n",
    "    \n",
    "        ##### Run Boosting (change if not supported)\n",
    "        \n",
    "    if Boost == \"Yes\":\n",
    "        \n",
    "        # AdaBoost\n",
    "    \n",
    "        from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "        aboosting = AdaBoostClassifier(base_estimator=model)\n",
    "        aboosting.fit(X_train, y_train)\n",
    "        aboosting_predictions = aboosting.predict(X_test)\n",
    "        aboosting_probabilities = aboosting.predict_proba(X_test)\n",
    "\n",
    "        aboost_probability_list = [] # Becomes the list of probabilities\n",
    "        for i in aboosting_probabilities:\n",
    "            aboost_probability_list.append(i[1])\n",
    "        aboosting_probabilities = aboost_probability_list\n",
    "\n",
    "        abst_acc_score = accuracy_score(y_test, aboosting_predictions)\n",
    "        bbst_con_matrix = confusion_matrix(y_test, aboosting_predictions)\n",
    "        abst_class_rep = classification_report(y_test, aboosting_predictions)\n",
    "        abst_roc_auc = roc_auc_score(y_test, aboosting_probabilities)\n",
    "        \n",
    "        print \"AdaBoosting Classifiers \\n\", aboosting.base_estimator_, \"\\n\"\n",
    "        print \"AdaBoosting Accuracy Score \\n\", abst_acc_score, \"\\n\"\n",
    "        print \"AdaBoosting Confusion Matrix \\n\", abst_con_matrix, \"\\n\"\n",
    "        print \"AdaBoosting Classification Report \\n\", abst_class_rep, \"\\n\"\n",
    "        print \"AdaBoosting ROC-AUC Score \\n\", abst_roc_auc, \"\\n\"\n",
    "        \n",
    "        # GradientBoosting\n",
    "    \n",
    "        from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "        gboosting = GradientBoostingClassifier(init=model)\n",
    "        gboosting.fit(X_train, y_train)\n",
    "        gboosting_predictions = gboosting.predict(X_test)\n",
    "        gboosting_probabilities = gboosting.predict_proba(X_test)\n",
    "\n",
    "        gboost_probability_list = [] # Becomes the list of probabilities\n",
    "        for i in gboosting_probabilities:\n",
    "            gboost_probability_list.append(i[1])\n",
    "        gboosting_probabilities = gboost_probability_list\n",
    "\n",
    "        gbst_acc_score = accuracy_score(y_test, gboosting_predictions)\n",
    "        gbst_con_matrix = confusion_matrix(y_test, gboosting_predictions)\n",
    "        gbst_class_rep = classification_report(y_test, gboosting_predictions)\n",
    "        gbst_roc_auc = roc_auc_score(y_test, gboosting_probabilities)\n",
    "        \n",
    "        print \"GradientBoosting Classifiers \\n\", gboosting.base_estimator_, \"\\n\"\n",
    "        print \"GradientBoosting Accuracy Score \\n\", gbst_acc_score, \"\\n\"\n",
    "        print \"GradientBoosting Confusion Matrix \\n\", gbst_con_matrix, \"\\n\"\n",
    "        print \"GradientBoosting Classification Report \\n\", gbst_class_rep, \"\\n\"\n",
    "        print \"GradientBoosting ROC-AUC Score \\n\", gbst_roc_auc, \"\\n\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Species', u'Block', u'Trap', u'Latitude', u'Longitude',\n",
       "       u'AddressAccuracy', u'NumMosquitos', u'WnvPresent', u'YMD', u'PIPIENS',\n",
       "       u'RESTUANS', u'SALINARIUS', u'TERRITANS', u'Station', u'Tmax', u'Tmin',\n",
       "       u'DewPoint', u'WetBulb', u'Sunrise', u'Sunset', u'PrecipTotal',\n",
       "       u'StnPressure', u'SeaLevel', u'ResultSpeed', u'ResultDir', u'AvgSpeed',\n",
       "       u'Tavg_int', u'Normal_Temp', u'Depart_calc', u'RA', u'BR', u'TS', u'HZ',\n",
       "       u'SN', u'FG', u'FG+', u'FU', u'DZ', u'VC', u'MI', u'BC',\n",
       "       u'Days_Since_Spray', u'Dist_to_Closest_Spray', u'Week',\n",
       "       u'DaylightMinutes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Species', u'Block', u'Trap', u'Latitude', u'Longitude',\n",
       "       u'AddressAccuracy', u'YMD', u'PIPIENS', u'RESTUANS', u'SALINARIUS',\n",
       "       u'TERRITANS', u'Station', u'Tmax', u'Tmin', u'DewPoint', u'WetBulb',\n",
       "       u'Sunrise', u'Sunset', u'PrecipTotal', u'StnPressure', u'SeaLevel',\n",
       "       u'ResultSpeed', u'ResultDir', u'AvgSpeed', u'Tavg_int', u'Normal_Temp',\n",
       "       u'Depart_calc', u'RA', u'BR', u'TS', u'HZ', u'SN', u'FG', u'FG+', u'FU',\n",
       "       u'DZ', u'VC', u'MI', u'BC', u'Days_Since_Spray',\n",
       "       u'Dist_to_Closest_Spray', u'Week', u'DaylightMinutes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Miranda's investigation:\n",
    "Highest potential columns:  \n",
    "PIPIENS  \n",
    "Tavg  \n",
    "DewPoint  \n",
    "WetBulb  \n",
    "PrecipTotal  \n",
    "Days_Since_Spray  \n",
    "Dist_to_Closest_Spray  \n",
    "FG   \n",
    "BR    \n",
    "HZ  \n",
    "VC  \n",
    "Week  \n",
    "DaylightMinutes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at particular columns and run the functions.  \n",
    "\n",
    "# Narrowing columns to a few of high interest.\n",
    "columns_of_interest = [\"PIPIENS\", \"Tavg_int\", \"PrecipTotal\", \"Days_Since_Spray\", \n",
    "                      \"Dist_to_Closest_Spray\", \"Week\", \"DaylightMinutes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This list has all possible based on Miranda's list\n",
    "columns_of_interest = [\"PIPIENS\", \"Tavg_int\", \"DewPoint\", \"WetBulb\", \"PrecipTotal\", \n",
    "                      \"Days_Since_Spray\", \"Dist_to_Closest_Spray\", \"FG\", \"BR\", \n",
    "                      \"HZ\", \"VC\", \"Week\", \"DaylightMinutes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This list uses almost everything with a value:\n",
    "columns_of_interest = [\"Block\", \"Latitude\", \"Longitude\", \"AddressAccuracy\", \n",
    "                      \"PIPIENS\", \"RESTUANS\", \"SALINARIUS\", \"TERRITANS\", \"Tmax\", \"Tmin\",\n",
    "                      \"Tavg_int\", \"DewPoint\", \"WetBulb\", \"PrecipTotal\", \"StnPressure\", \n",
    "                      \"SeaLevel\", \"ResultSpeed\", \"ResultDir\", \"AvgSpeed\", \"Normal_Temp\", \n",
    "                      \"RA\", \"BR\", \"TS\", \"HZ\", \"SN\", \"FG\", \"FU\", \"DZ\", \"VC\", \"MI\", \"BC\", \n",
    "                      \"Days_Since_Spray\", \"Dist_to_Closest_Spray\", \"Week\", \"DaylightMinutes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = train_data[columns_of_interest]\n",
    "y = train_data[\"WnvPresent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary models:\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recall\n",
    "\n",
    "### Scale = \"Yes\"; skip otherwise\n",
    "### TTS = \"Yes\" or \"No\" on whether or not to run a train/test split\n",
    "### X = Pre-defined dataframe and its columns of interest\n",
    "### y = Pre-defined dataframe target column\n",
    "### model_to_run = Model() wishing to run this test on\n",
    "### grid_search_dictionary = parameter dictionary to feed \n",
    "            ### into grid_search for the model of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Scores \n",
      "[ 0.94558824  0.9455081   0.9455081   0.9455081   0.94690265  0.94690265\n",
      "  0.94690265  0.94690265  0.94690265  0.94690265] \n",
      "\n",
      "Accuracy Score \n",
      "0.952200825309 \n",
      "\n",
      "Confusion Matrix \n",
      "[[2769    0]\n",
      " [ 139    0]] \n",
      "\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      2769\n",
      "          1       0.00      0.00      0.00       139\n",
      "\n",
      "avg / total       0.91      0.95      0.93      2908\n",
      "\n",
      "\n",
      "ROC-AUC Score \n",
      "0.673682938806 \n",
      "\n",
      "Bagging Classifiers \n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "\n",
      "Bagging Accuracy Score \n",
      "0.952200825309 \n",
      "\n",
      "Bagging Confusion Matrix \n",
      "[[2769    0]\n",
      " [ 139    0]] \n",
      "\n",
      "Bagging Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      2769\n",
      "          1       0.00      0.00      0.00       139\n",
      "\n",
      "avg / total       0.91      0.95      0.93      2908\n",
      "\n",
      "Bagging ROC-AUC Score \n",
      "0.676119992413 \n",
      "\n",
      "Grid Search Best Params \n",
      "{'penalty': 'l1', 'C': 0.001} \n",
      "\n",
      "Grid Search Best Score \n",
      "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "\n",
      "GS Accuracy Score \n",
      "0.952200825309 \n",
      "\n",
      "GS Confusion Matrix \n",
      "[[2769    0]\n",
      " [ 139    0]] \n",
      "\n",
      "GS Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      2769\n",
      "          1       0.00      0.00      0.00       139\n",
      "\n",
      "avg / total       0.91      0.95      0.93      2908\n",
      "\n",
      "\n",
      "GS ROC-AUC Score \n",
      "0.5 \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'boosting' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-47f1a4b14275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     }\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Yes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Yes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Yes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-6894c8e50939>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(Scale, TTS, Boost, X, y, model_to_run, grid_search_dictionary)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0maboosting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0maboosting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0maboosting_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboosting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0maboosting_probabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboosting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'boosting' is not defined"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "# Set up the parameters for GridSearch\n",
    "log_dict = {\n",
    "    'penalty':('l1', 'l2'),\n",
    "    'C':[0.001, 0.01, 0.1, 1.0, 2.0, 5.0, 10.0]\n",
    "    }\n",
    "\n",
    "evaluate_model(\"Yes\", \"Yes\", \"Yes\", X, y, LogisticRegression(), log_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Scores \n",
      "[ 0.94256259  0.94108984  0.93372607  0.94698085  0.93961708  0.94108984\n",
      "  0.94403535  0.94837758  0.95125554  0.95125554] \n",
      "\n",
      "Accuracy Score \n",
      "0.943947730399 \n",
      "\n",
      "Confusion Matrix \n",
      "[[2733   29]\n",
      " [ 134   12]] \n",
      "\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      2762\n",
      "          1       0.29      0.08      0.13       146\n",
      "\n",
      "avg / total       0.92      0.94      0.93      2908\n",
      "\n",
      "\n",
      "ROC-AUC Score \n",
      "0.681436173906 \n",
      "\n",
      "Bagging Classifiers \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform') \n",
      "\n",
      "Bagging Accuracy Score \n",
      "0.945323246217 \n",
      "\n",
      "Bagging Confusion Matrix \n",
      "[[2737   25]\n",
      " [ 134   12]] \n",
      "\n",
      "Bagging Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      2762\n",
      "          1       0.32      0.08      0.13       146\n",
      "\n",
      "avg / total       0.92      0.95      0.93      2908\n",
      "\n",
      "Bagging ROC-AUC Score \n",
      "0.78018087945 \n",
      "\n",
      "Grid Search Best Params \n",
      "{'n_neighbors': 10, 'weights': 'uniform'} \n",
      "\n",
      "Grid Search Best Score \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform') \n",
      "\n",
      "GS Accuracy Score \n",
      "0.949105914718 \n",
      "\n",
      "GS Confusion Matrix \n",
      "[[2754    8]\n",
      " [ 140    6]] \n",
      "\n",
      "GS Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      2762\n",
      "          1       0.43      0.04      0.07       146\n",
      "\n",
      "avg / total       0.93      0.95      0.93      2908\n",
      "\n",
      "\n",
      "GS ROC-AUC Score \n",
      "0.793047523633 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN Classifier\n",
    "\n",
    "# Good to check in both high number of columns, and low.\n",
    "# This run is low\n",
    "\n",
    "knn_dict = {\n",
    "    'n_neighbors': [1, 2, 3, 5, 10, 20, 50],\n",
    "    'weights': ('uniform', 'distance')\n",
    "    }\n",
    "\n",
    "\n",
    "evaluate_model(\"Yes\", \"Yes\", \"No\", X, y, KNeighborsClassifier(), knn_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Scores \n",
      "[ 0.93235294  0.92488954  0.94108984  0.93814433  0.9439528   0.94247788\n",
      "  0.93362832  0.93362832  0.94100295  0.93362832] \n",
      "\n",
      "Accuracy Score \n",
      "0.937414030261 \n",
      "\n",
      "Confusion Matrix \n",
      "[[2707   52]\n",
      " [ 130   19]] \n",
      "\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.97      2759\n",
      "          1       0.27      0.13      0.17       149\n",
      "\n",
      "avg / total       0.92      0.94      0.93      2908\n",
      "\n",
      "\n",
      "ROC-AUC Score \n",
      "0.723140375245 \n",
      "\n",
      "Bagging Classifiers \n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best') \n",
      "\n",
      "Bagging Accuracy Score \n",
      "0.945323246217 \n",
      "\n",
      "Bagging Confusion Matrix \n",
      "[[2725   34]\n",
      " [ 125   24]] \n",
      "\n",
      "Bagging Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.97      2759\n",
      "          1       0.41      0.16      0.23       149\n",
      "\n",
      "avg / total       0.93      0.95      0.93      2908\n",
      "\n",
      "Bagging ROC-AUC Score \n",
      "0.795704600685 \n",
      "\n",
      "Grid Search Best Params \n",
      "{'max_features': 0.4, 'min_samples_split': 3, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 8} \n",
      "\n",
      "Grid Search Best Score \n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=8,\n",
      "            max_features=0.4, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=8,\n",
      "            min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best') \n",
      "\n",
      "GS Accuracy Score \n",
      "0.949105914718 \n",
      "\n",
      "GS Confusion Matrix \n",
      "[[2754    5]\n",
      " [ 143    6]] \n",
      "\n",
      "GS Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      2759\n",
      "          1       0.55      0.04      0.07       149\n",
      "\n",
      "avg / total       0.93      0.95      0.93      2908\n",
      "\n",
      "\n",
      "GS ROC-AUC Score \n",
      "0.811268064735 \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'boosting' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-46cd770363be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     }\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Yes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Yes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtree_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-6894c8e50939>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(Scale, TTS, Boost, X, y, model_to_run, grid_search_dictionary)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0maboosting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0maboosting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0maboosting_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboosting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0maboosting_probabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboosting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'boosting' is not defined"
     ]
    }
   ],
   "source": [
    "# Decision tree:\n",
    "\n",
    "# With this setup, better to run with more columns, so\n",
    "# columns_of_interest takes high amount\n",
    "\n",
    "dtree_dict = {\n",
    "    'criterion':('gini', 'entropy'),\n",
    "    'max_features':[2, 3, 5, 8, 10, 0.2, 0.4, 0.6, 0.8, \"sqrt\", \"log2\", None],\n",
    "    'max_depth':[2, 3, 5, 8, 10, None],\n",
    "    'min_samples_split':[2, 3, 5, 8, 10, 0.2, 0.4, 0.6, 0.8],\n",
    "    'min_samples_leaf': [2, 3, 5, 8, 10, 0.2, 0.3, 0.4, 0.5]\n",
    "    }\n",
    "\n",
    "evaluate_model(\"No\", \"Yes\", \"Yes\", X, y, DecisionTreeClassifier(), dtree_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random forest:\n",
    "\n",
    "\n",
    "rforest_dict = {\n",
    "    'criterion':('gini', 'entropy'),\n",
    "    'n_estimators':[2, 4, 7, 10, 20],\n",
    "    'max_features':[2, 3, 5, 8, 10, 0.2, 0.4, 0.6, 0.8, \"sqrt\", \"log2\", None],\n",
    "    'min_samples_split':[2, 3, 5, 8, 10, 0.2, 0.4, 0.6, 0.8],\n",
    "    'min_samples_leaf': [2, 3, 5, 8, 10, 0.2, 0.3, 0.4, 0.5]\n",
    "    }\n",
    "\n",
    "rforest_model = evaluate_model(\"No\", \"Yes\", \"Yes\", X, y, RandomForestClassifier(), rforest_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Scores \n",
      "[ 0.94845361  0.94845361  0.94845361  0.94845361  0.94845361  0.94845361\n",
      "  0.94845361  0.94985251  0.94977843  0.94977843] \n",
      "\n",
      "Accuracy Score \n",
      "0.946354883081 \n",
      "\n",
      "Confusion Matrix \n",
      "[[2752    0]\n",
      " [ 156    0]] \n",
      "\n",
      "Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      2752\n",
      "          1       0.00      0.00      0.00       156\n",
      "\n",
      "avg / total       0.90      0.95      0.92      2908\n",
      "\n",
      "\n",
      "ROC-AUC Score \n",
      "0.481768504025 \n",
      "\n",
      "Bagging Classifiers \n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "Bagging Accuracy Score \n",
      "0.905433287483 \n",
      "\n",
      "Bagging Confusion Matrix \n",
      "[[2632  120]\n",
      " [ 155    1]] \n",
      "\n",
      "Bagging Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.96      0.95      2752\n",
      "          1       0.01      0.01      0.01       156\n",
      "\n",
      "avg / total       0.89      0.91      0.90      2908\n",
      "\n",
      "Bagging ROC-AUC Score \n",
      "0.656662287567 \n",
      "\n",
      "Grid Search Best Params \n",
      "{'kernel': 'linear', 'C': 0.001} \n",
      "\n",
      "Grid Search Best Score \n",
      "SVC(C=0.001, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "GS Accuracy Score \n",
      "0.946354883081 \n",
      "\n",
      "GS Confusion Matrix \n",
      "[[2752    0]\n",
      " [ 156    0]] \n",
      "\n",
      "GS Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      2752\n",
      "          1       0.00      0.00      0.00       156\n",
      "\n",
      "avg / total       0.90      0.95      0.92      2908\n",
      "\n",
      "\n",
      "GS ROC-AUC Score \n",
      "0.66821332737 \n",
      "\n",
      "Boosting Classifiers \n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "Boosting Accuracy Score \n",
      "0.946354883081 \n",
      "\n",
      "Boosting Confusion Matrix \n",
      "[[2752    0]\n",
      " [ 156    0]] \n",
      "\n",
      "Boosting Classification Report \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      2752\n",
      "          1       0.00      0.00      0.00       156\n",
      "\n",
      "avg / total       0.90      0.95      0.92      2908\n",
      "\n",
      "\n",
      "Boosting ROC-AUC Score \n",
      "0.580049008646 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM - Trying without modifying the function\n",
    "\n",
    "svm_dict = {\n",
    "    'C':[0.001, 0.01, 0.1, 1.0, 2.0, 5.0, 10.0],\n",
    "    'kernel':('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "}\n",
    "\n",
    "evaluate_model(\"Yes\", \"Yes\", \"Yes\", X, y, SVC(probability=True), svm_dict)\n",
    "\n",
    "# Note: probability=True to actually get probabilities, otherwise\n",
    "# function will throw an error (.predict_proba will not work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get an output of probabilities\n",
    "Re-do the function to take in the test list and output the probability list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Include the Id column here for the actual output\n",
    "X_to_test = test_data[columns_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Mega Function to run all of the models of relevance ###\n",
    "# Mostly derived from 6.08 work and Project 3, with a couple modifications #\n",
    "\n",
    "### NEED TO MODIFY FUNCTION BEFORE RUNNING MODEL \n",
    "### IF WISHING TO USE model_metric (also needs commented back in)\n",
    "\n",
    "### Scale = \"Yes\"; skip otherwise\n",
    "### TTS = \"Yes\" or \"No\" on whether or not to run a train/test split\n",
    "### X = Pre-defined dataframe and its columns of interest\n",
    "### y = Pre-defined dataframe target column\n",
    "### model_to_run = Model() wishing to run this test on\n",
    "### grid_search_dictionary = parameter dictionary to feed \n",
    "            ### into grid_search for the model of interest\n",
    "\n",
    "def evaluate_model(Scale, TTS, X, y, model_to_run, grid_search_dictionary, X_to_test):\n",
    "    \n",
    "    if Scale == \"Yes\":\n",
    "        from sklearn.preprocessing import Normalizer\n",
    "        normalizer = Normalizer()\n",
    "        X = normalizer.fit_transform(X)\n",
    "        \n",
    "    if TTS == \"Yes\":\n",
    "        # Perform the train/test split:\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)   \n",
    "        \n",
    "    if TTS == \"No\":\n",
    "        # Skip TTS:\n",
    "        X_train = X\n",
    "        X_test = X\n",
    "        y_train = y\n",
    "        y_test = y\n",
    "    \n",
    "    ##### Run the model\n",
    "    model = model_to_run\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    probabilities = model.predict_proba(X_test) # Need the second value\n",
    "    \n",
    "    probability_list = [] # Becomes the list of probabilities\n",
    "    for i in probabilities:\n",
    "        probability_list.append(i[1])\n",
    "    probabilities = probability_list\n",
    "        \n",
    "    \n",
    "    # Create cross-val score on train\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    # Perform 10-fold cross validation\n",
    "    trn_cv_scores = cross_val_score(model, X_train, y_train, cv=10)\n",
    "    \n",
    "    # Create scores on test group\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    # Comment in if running a model with this attribute\n",
    "    # model_metric = model.feature_importances_   \n",
    "    # print model_metric\n",
    "    \n",
    "        # Model specific output attribute\n",
    "        # Have to reassign each function run\n",
    "    \n",
    "    acc_score = accuracy_score(y_test, predictions)\n",
    "    con_matrix = confusion_matrix(y_test, predictions)\n",
    "    class_rep = classification_report(y_test, predictions)\n",
    "    roc_auc = roc_auc_score(y_test, probabilities)\n",
    "\n",
    "    \n",
    "    ##### Run Bagging\n",
    "    from sklearn.ensemble import BaggingClassifier\n",
    "    \n",
    "    bagging = BaggingClassifier(base_estimator=model)\n",
    "    bagging.fit(X_train, y_train)\n",
    "    bagging_predictions = bagging.predict(X_test)\n",
    "    bagging_probabilities = bagging.predict_proba(X_test)\n",
    "    \n",
    "    bag_probability_list = [] # Becomes the list of probabilities\n",
    "    for i in bagging_probabilities:\n",
    "        bag_probability_list.append(i[1])\n",
    "    bagging_probabilities = bag_probability_list\n",
    "    \n",
    "    bg_acc_score = accuracy_score(y_test, bagging_predictions)\n",
    "    bg_con_matrix = confusion_matrix(y_test, bagging_predictions)\n",
    "    bg_class_rep = classification_report(y_test, bagging_predictions)\n",
    "    bg_roc_auc = roc_auc_score(y_test, bagging_probabilities)\n",
    "    \n",
    "    \n",
    "    ##### Run a GridSearch\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    # Run 10-fold cross validation on the bagged model\n",
    "    grid_search = GridSearchCV(model, grid_search_dictionary, cv=10, n_jobs = -1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    grid_search_predictions = grid_search.predict(X_test)\n",
    "    grid_search_probabilities = grid_search.predict_proba(X_test)\n",
    "    \n",
    "    gs_probability_list = [] # Becomes the list of probabilities\n",
    "    for i in grid_search_probabilities:\n",
    "        gs_probability_list.append(i[1])\n",
    "    grid_search_probabilities = gs_probability_list\n",
    "    \n",
    "    gs_acc_score = accuracy_score(y_test, grid_search_predictions)\n",
    "    gs_con_matrix = confusion_matrix(y_test, grid_search_predictions)\n",
    "    gs_class_rep = classification_report(y_test, grid_search_predictions)\n",
    "    gs_roc_auc = roc_auc_score(y_test, grid_search_probabilities)\n",
    "    \n",
    "    ##### Run Boosting\n",
    "    \n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    \n",
    "    boosting = AdaBoostClassifier(base_estimator=model)\n",
    "    boosting.fit(X_train, y_train)\n",
    "    boosting_predictions = boosting.predict(X_test)\n",
    "    boosting_probabilities = boosting.predict_proba(X_test)\n",
    "    \n",
    "    boost_probability_list = [] # Becomes the list of probabilities\n",
    "    for i in boosting_probabilities:\n",
    "        boost_probability_list.append(i[1])\n",
    "    boosting_probabilities = boost_probability_list\n",
    "    \n",
    "    bst_acc_score = accuracy_score(y_test, boosting_predictions)\n",
    "    bst_con_matrix = confusion_matrix(y_test, boosting_predictions)\n",
    "    bst_class_rep = classification_report(y_test, boosting_predictions)\n",
    "    bst_roc_auc = roc_auc_score(y_test, boosting_probabilities)\n",
    "    \n",
    "    # Get final output list\n",
    "    final_predictions = boosting.predict_proba(X_to_test)\n",
    "    \n",
    "    # See the outputs\n",
    "    print \"Cross Val Scores \\n\", trn_cv_scores, \"\\n\"\n",
    "    # print \"Model Attribute \\n\", model_metric, \"\\n\"\n",
    "            # Add back in if used above\n",
    "    print \"Accuracy Score \\n\", acc_score, \"\\n\"\n",
    "    print \"Confusion Matrix \\n\", con_matrix, \"\\n\"\n",
    "    print \"Classification Report \\n\", class_rep, \"\\n\"\n",
    "    print \"ROC-AUC Score \\n\", roc_auc, \"\\n\"\n",
    "    \n",
    "    print \"Bagging Classifiers \\n\", bagging.base_estimator_, \"\\n\"\n",
    "    print \"Bagging Accuracy Score \\n\", bg_acc_score, \"\\n\"\n",
    "    print \"Bagging Confusion Matrix \\n\", bg_con_matrix, \"\\n\"\n",
    "    print \"Bagging Classification Report \\n\", bg_class_rep\n",
    "    print \"Bagging ROC-AUC Score \\n\", bg_roc_auc, \"\\n\"\n",
    "    \n",
    "    print \"Boosting Classifiers \\n\", boosting.base_estimator_, \"\\n\"\n",
    "    print \"Bagging Accuracy Score \\n\", bst_acc_score, \"\\n\"\n",
    "    print \"Bagging Confusion Matrix \\n\", bst_con_matrix, \"\\n\"\n",
    "    print \"Bagging Classification Report \\n\", bst_class_rep, \"\\n\"\n",
    "    print \"Bagging ROC-AUC Score \\n\", bst_roc_auc, \"\\n\"\n",
    "    \n",
    "    print \"Grid Search Best Params \\n\", grid_search.best_params_, \"\\n\"\n",
    "    print \"Grid Search Best Score \\n\", grid_search.best_estimator_, \"\\n\"\n",
    "    print \"GS Accuracy Score \\n\", gs_acc_score, \"\\n\"\n",
    "    print \"GS Confusion Matrix \\n\", gs_con_matrix, \"\\n\"\n",
    "    print \"GS Classification Report \\n\", gs_class_rep, \"\\n\"\n",
    "    print \"GS ROC-AUC Score \\n\", gs_roc_auc, \"\\n\"\n",
    "    \n",
    "    print \"Generating output dataframe: \", \"\\n\"\n",
    "    return final_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_final_model = evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df = test_data[\"Id\"]\n",
    "submission_df[\"WnvPresent\"] = run_final_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
